{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abeb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.captureWarnings(True)\n",
    "\n",
    "import json\n",
    "import pkg_resources\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import descarteslabs as dl\n",
    "from descarteslabs import workflows as wf\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from shapely import geometry as sgeom\n",
    "\n",
    "import will_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1c5ca",
   "metadata": {},
   "source": [
    "### NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cc942",
   "metadata": {},
   "source": [
    "In this section we are going to calculate the NDVI for an area of Brazil using workflows. We will employ workflows functionality that allows us to mask for clouds, create a daily composite of images, apply a moving window average of the images, and lastly deploy the NDVI workflow across a large AOI using workflows jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0af273",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = 'sentinel-2:L1C'\n",
    "start_datetime='2018-01-01'\n",
    "end_datetime='2021-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b42bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 075785a12330c1399615eb88b00fa6069a083c4870a89c9d\n",
      "[      ] | Steps: 0/0 | Stage: SUCCEEDED                                      "
     ]
    }
   ],
   "source": [
    "#import yolo country\n",
    "tomato_aoi = json.load(open('yolo.geojson'))\n",
    "\n",
    "# #Get UTM EPSG code\n",
    "shapely_aoi = sgeom.shape(tomato_aoi['features'][0]['geometry'])\n",
    "lat, lon = shapely_aoi.centroid.y, shapely_aoi.centroid.x\n",
    "utm_epsg = utils.wgs_to_epsg(lat, lon)\n",
    "\n",
    "#Create workflows context\n",
    "wf_ctx = wf.GeoContext(\n",
    "                geometry=tomato_aoi['features'][0]['geometry'],\n",
    "                resolution=10.0,\n",
    "                crs=f'EPSG:{utm_epsg}',\n",
    "                bounds_crs='EPSG:4326')\n",
    "\n",
    "# #Convert to a tile \n",
    "wf_ctx_data = wf_ctx.compute(progress_bar=True)\n",
    "reflat, reflon = wf_ctx_data['bounds'][1], wf_ctx_data['bounds'][0]\n",
    "tilesize= max(wf_ctx_data['arr_shape'])\n",
    "tile = dl.scenes.DLTile.from_latlon(reflat, reflon, wf_ctx_data['resolution'], tilesize, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb4d0e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-60bdcb1e137e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define Workflows GeoContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m geoctx = dl.scenes.AOI(sg.shape(state.geometry).simplify(0.01),\n\u001b[0m\u001b[1;32m      7\u001b[0m                        crs=\"EPSG:4326\", resolution=0.01)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sg' is not defined"
     ]
    }
   ],
   "source": [
    "# Get shape of Yolo county in California\n",
    "places_client = dl.Places()\n",
    "state = places_client.shape(\"north-america_united-states_california_sacramento-valley_yolo\")\n",
    "\n",
    "# Define Workflows GeoContext\n",
    "geoctx = dl.scenes.AOI(sg.shape(state.geometry).simplify(0.01),\n",
    "                       crs=\"EPSG:4326\", resolution=0.01)\n",
    "\n",
    "# Display on a map:\n",
    "dsp.GeoJSON(geojson.Feature(geometry=geoctx.geometry))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f88e5f",
   "metadata": {},
   "source": [
    "Here we start to define the workflow. We will use Sentinel-2 imagery which has a resolution of 10 meters. In this next block of code, comments have been added before each step explaining what is happening in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b380dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a basic workflow defining the product, date range, and finally picking which bands we want\n",
    "sent2 = wf.ImageCollection.from_id(product_id=product_id,\n",
    "                                   start_datetime=start_datetime,\n",
    "                                   end_datetime=end_datetime\n",
    "                                   ).pick_bands('derived:ndvi cloud-mask')\n",
    "\n",
    "\n",
    "\n",
    "# Also import the 2020 CDL \n",
    "cdl = wf.ImageCollection.from_id(\"usda:cdl:v1\", start_datetime=\"2020-12-31\", end_datetime=\"2021-01-01\")\n",
    "\n",
    "s2 = wf.ImageCollection.from_id(product_id=product_id,\n",
    "                                   start_datetime=start_datetime,\n",
    "                                   end_datetime=end_datetime\n",
    "                                   ).pick_bands('red green blue').mask(cdl.mosaic() != 54) \n",
    "\n",
    "#Here we mask all pixels in each image where the cloud mask is equal to 1.\n",
    "#We then just return the ndvi band using pick_bands. \n",
    "ndvi_masked = sent2.map(lambda img: img.mask(img.pick_bands('cloud-mask') == 1)).pick_bands('derived:ndvi')\n",
    "\n",
    "# And mask by the CDL = 54, which limits the calculation to only tomatoers\n",
    "ndvi_masked = ndvi_masked.mask(cdl.mosaic() != 54) \n",
    "\n",
    "\n",
    "#This step groups the images by day. If there is more than one image on a day in the AOI\n",
    "#Then they are grouped into an Image collection together. This step also easily exposes\n",
    "#The date information for all the images in our time window\n",
    "ndvi_grouped = ndvi_masked.groupby(dates=('year', 'month', 'day'))\n",
    "\n",
    "#Next, we create a composite image for each day by taking the mean across images\n",
    "ndvi_mean = ndvi_grouped.mean('images')\n",
    "\n",
    "#Next we apply a moving window to the grouped images. In this case, we are combining the images\n",
    "#in the window with a mean operator and making sure the group information is included in the \n",
    "#properties of the new image. We are including the current image, plus the two images directly\n",
    "#before and after\n",
    "ndvi_windowed = ndvi_mean.map_window(lambda back, img, fwd: \n",
    "                                     wf.concat(back, img, fwd)\n",
    "                                     .mean('images')\n",
    "                                     .with_properties(group=img.properties['group']), back=2, fwd=2)\n",
    "\n",
    "#Now since we want to summarize the NDVI over the entire AOI using a mean, we will return the sum\n",
    "#and count of the unmasked pixels in each group. Additionally, we will return the group which is the date\n",
    "#of the central image in the window. We use workflows containers to organize the results. \n",
    "ndvi_stats = ndvi_windowed.map(lambda img: wf.Dict[wf.Str, wf.Any]({\n",
    "                                      'sum': img.sum('pixels')['derived:ndvi'],\n",
    "                                      'count': img.count('pixels')['derived:ndvi'],\n",
    "                                      'group': img.properties['group']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908eb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the groups and split the AOI into DL Tiles\n",
    "groups = ndvi_grouped.groups.keys().compute(wf_ctx, progress_bar=True)\n",
    "tiles = dl.scenes.DLTile.from_shape(tomato_aoi, 10, 1024, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit the workflows jobs using compute and setting block=False\n",
    "jobs = list(map(lambda ctx: ndvi_stats.compute(ctx, block=False), tiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0c5ec",
   "metadata": {},
   "source": [
    "In the step below, we are going to combine the output of the jobs by group. We use a function located in utils.py \n",
    "called as_completed which loops over our job list and yeilds jobs as they complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594107c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = {key: 0 for key in groups}\n",
    "total_count = {key: 0 for key in groups}\n",
    "for job in tqdm(utils.as_completed(jobs, interval_sec=1), total=len(jobs)):\n",
    "    data = job.result(progress_bar=True)\n",
    "    for entry in data:\n",
    "        if not np.ma.is_masked(entry['sum']):\n",
    "            total_sum[entry['group']] += entry['sum']\n",
    "            total_count[entry['group']] += entry['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b84549",
   "metadata": {},
   "source": [
    "All that is left to do is combine the information into a couple lists for plotting or saving later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00357a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_vals = []\n",
    "group_dates = []\n",
    "for key in groups:\n",
    "    summed = total_sum[key]\n",
    "    counted = total_count[key]\n",
    "    if summed > 0:\n",
    "        ndvi_vals.append(summed/counted)\n",
    "    else:\n",
    "        ndvi_vals.append(np.nan)\n",
    "    \n",
    "    group_dates.append(pd.to_datetime(str(key), format='(%Y, %m, %d)'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392189dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these lists to text files for further processing\n",
    "with open('group_dates.txt', 'w') as f:\n",
    "    for item in group_dates:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "textfile.close()\n",
    "\n",
    "with open('ndvi_vals.txt', 'w') as f:\n",
    "    for item in ndvi_vals:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126f4a17",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6ad59",
   "metadata": {},
   "source": [
    "In this section we are calculating the Growing Degree Days, Precipitation, and Soil Moisture content in a daily intervals for the entire year. We define a basic workflow object below and then expand on it for each of the layers we are going to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe69aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncepflow = wf.ImageCollection.from_id('ncep:cfsr-v2:daily:v1', \n",
    "                                       start_datetime=start_datetime, \n",
    "                                       end_datetime=end_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c6ebe",
   "metadata": {},
   "source": [
    "#### Growing Degree Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Growing_degree-day#GDD_calculation\n",
    "# NCEP data is in 0.01 K\n",
    "tmin, tmax =  ncepflow.unpack_bands('tmin tmax')\n",
    "\n",
    "gdd_base = 283.\n",
    "gdd = (((tmax + tmin) / (2*100)) - gdd_base).clip_values(min=0.)\n",
    "gdd_ts = gdd.map(lambda img: wf.Dict[wf.Datetime, wf.Float].from_pairs([(img.properties['date'], img.median('pixels')['tmax_add_tmin'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ef624",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdd_res = gdd_ts.compute(tile_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdd_dates = []\n",
    "gdd_vals = []\n",
    "for res in gdd_res:\n",
    "    key = list(res.keys())[0]\n",
    "    gdd_dates.append(pd.to_datetime(key.split('T')[0], format='%Y-%m-%d'))\n",
    "    gdd_vals.append(res[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these lists to text files for further processing\n",
    "with open('gdd_vals.txt', 'w') as f:\n",
    "    for item in gdd_vals:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7748b78",
   "metadata": {},
   "source": [
    "#### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = ncepflow.pick_bands('prec')\n",
    "precip_ts = precip.map(lambda img: wf.Dict[wf.Datetime, wf.Float].from_pairs([(img.properties['date'], img.max('pixels')['prec'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dba9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_res = precip_ts.compute(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48860b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_dates = []\n",
    "precip_vals = []\n",
    "for res in precip_res:\n",
    "    key = list(res.keys())[0]\n",
    "    precip_dates.append(pd.to_datetime(key.split('T')[0], format='%Y-%m-%d'))\n",
    "    precip_vals.append(res[key] * 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318f383",
   "metadata": {},
   "source": [
    "#### Soil Moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b446492",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_moisture = ncepflow.pick_bands('soilmoist2')\n",
    "soil_moisture_ts = soil_moisture.map(lambda img: wf.Dict[wf.Datetime, wf.Float].from_pairs([(img.properties['date'], img.median('pixels')['soilmoist2'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_res = soil_moisture_ts.compute(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_dates = []\n",
    "soil_vals = []\n",
    "for res in soil_res:\n",
    "    key = list(res.keys())[0]\n",
    "    soil_dates.append(pd.to_datetime(key.split('T')[0], format='%Y-%m-%d'))\n",
    "    soil_vals.append(res[key] * 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487b99a",
   "metadata": {},
   "source": [
    "Now lets plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba8236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabs = ['NDVI', 'GDDs', 'Precipitation (mm)', 'Soil Moisture (%)']\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n",
    "axs[0].plot(group_dates, ndvi_vals)\n",
    "# axs[1].plot(gdd_dates, gdd_vals)\n",
    "# axs[2].plot(precip_dates, precip_vals)\n",
    "# axs[3].plot(soil_dates, soil_vals)\n",
    "\n",
    "for (ax, lab) in zip(axs, ylabs):\n",
    "    ax.set_ylabel(lab, size=13)\n",
    "    ax.tick_params('both', labelsize=12)\n",
    "\n",
    "axs[-1].set_xlabel('Date', size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ad857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
